{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duper203/MLP_pytorch/blob/main/three-layer/variable_learningRate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_a1Rz3nVyJh"
      },
      "source": [
        "# Assignment 1 : MLP Classification (Pytorch)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI4mr7ETdFSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181998d3-3306-451a-b70c-e5404983de64"
      },
      "source": [
        "name = input(\"Name :\")\n",
        "ID = input(\"student ID :\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name :김혜수\n",
            "student ID :2110883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPLGGnO29MSa"
      },
      "source": [
        "## 실습\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDukFMhuUJvN"
      },
      "source": [
        "\n",
        "## Matrix 미분 정리\n",
        "$H = XW+b$</br>\n",
        "$L = f(H)$</br>\n",
        "$\\frac{\\partial L}{\\partial W} = \\frac{\\partial H}{\\partial W} \\times \\frac{\\partial L}{\\partial H} = \\frac{\\partial (XW+b)}{\\partial W} \\times\\frac{\\partial L}{\\partial H} = X *\\frac{\\partial L}{\\partial H}$</br>\n",
        "$\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial H} \\times \\frac{\\partial H}{\\partial X} = \\frac{\\partial L}{\\partial H} \\times \\frac{\\partial (XW+b)}{\\partial X} = \\frac{\\partial L}{\\partial H}*W$</br>\n",
        "$\\frac{\\partial L}{\\partial b}=1*\\frac{\\partial L}{\\partial H}$</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-fmKct3--PU"
      },
      "source": [
        "3 Layer Network를 완성하시오\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dec_jM7xqcmi"
      },
      "source": [
        "import torch\n",
        "\n",
        "class ThreeLayerNet(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size_one,hidden_size_two,output_size, std=1e-4):\n",
        "    super(ThreeLayerNet, self).__init__()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    #---------과제---------#\n",
        "    #네트워크를 설계해보세요#\n",
        "    #torch.nn.Linear가 MLP 한 층을 나타냅니다#\n",
        "    #Activation function도 잊지 마세요#\n",
        "    #! hidden size는 자유롭게 설계해보세요 !#\n",
        "    #---------과제---------#\n",
        "\n",
        "    self.layer1=torch.nn.Linear(input_size, hidden_size_one)\n",
        "    self.layer2=torch.nn.Linear(hidden_size_one, hidden_size_two)\n",
        "    self.layer3=torch.nn.Linear(hidden_size_two, output_size)\n",
        "    self.relu=torch.nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self, X, y = None):\n",
        "    #---------과제---------#\n",
        "    #feedfoward 부분을 코딩해보세요#\n",
        "    #천천히 순서대로 작성하시면 됩니다.#\n",
        "    #마지막에 softmax 잊지 마세요#\n",
        "    #최종 결과물 변수의 이름은 output으로 해주세요#\n",
        "    #---------과제---------#\n",
        "    feature1=self.relu(self.layer1(X))\n",
        "    feature2=self.relu(self.layer2(feature1))\n",
        "    feature3=self.relu(self.layer3(feature2))\n",
        "\n",
        "    output=torch.nn.functional.log_softmax(feature3, dim=1)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def accuracy(self, X, y):\n",
        "      p = self.forward(X)\n",
        "      pred = torch.argmax(p,dim=1)\n",
        "      acc = torch.sum(pred==y).float()/X.shape[0]*100\n",
        "\n",
        "      return acc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ-HRa3Y6BSH"
      },
      "source": [
        "#### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3wb5RRRQokx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b57fa9-e2da-43e4-f748-19f7377fdc9c"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU41dla3E-lK",
        "outputId": "c86763e7-43ad-43fc-8649-fa99a88387c6"
      },
      "source": [
        "print(\"shape of x_train :\",x_train.shape)\n",
        "print(\"shape of y_train :\",y_train.shape)\n",
        "print(\"shape of x_test :\",x_test.shape)\n",
        "print(\"shape of y_test :\",y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x_train : (60000, 28, 28)\n",
            "shape of y_train : (60000,)\n",
            "shape of x_test : (10000, 28, 28)\n",
            "shape of y_test : (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhwXBuLBCW5U"
      },
      "source": [
        "def preprocessing_data(x_train, x_test, y_train, y_test):\n",
        "    x_train = x_train[:5000]\n",
        "    y_train = y_train[:5000]\n",
        "    x_test = x_test[:1000]\n",
        "    y_test = y_test[:1000]\n",
        "\n",
        "    #change dtype\n",
        "    x_train = torch.from_numpy(x_train).cuda()\n",
        "    x_test = torch.from_numpy(x_test).cuda()\n",
        "\n",
        "    x_train = torch.tensor(x_train,dtype=torch.float64, device=\"cuda:0\")\n",
        "    y_train = torch.tensor(y_train,device=\"cuda:0\")\n",
        "\n",
        "    x_test = torch.tensor(x_test,dtype=torch.float64,device=\"cuda:0\")\n",
        "    y_test = torch.tensor(y_test,device=\"cuda:0\")\n",
        "\n",
        "    #reshaping : 2D -> 1D\n",
        "    x_train = x_train.reshape([x_train.shape[0],-1])\n",
        "    x_test = x_test.reshape(x_test.shape[0],-1)\n",
        "\n",
        "\n",
        "    #normalization : 값의 정규화\n",
        "    mean_value = torch.mean(x_train, dim=0)\n",
        "    x_train -= mean_value\n",
        "    x_train = x_train/255\n",
        "    x_test -= mean_value\n",
        "    x_test = x_test/255\n",
        "\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8JElsD8kjst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a1b740-8c82-460c-b930-33c1da01f060"
      },
      "source": [
        "x_train, x_test, y_train, y_test = preprocessing_data(x_train, x_test, y_train, y_test)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8ebaba95c783>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_train = torch.tensor(x_train,dtype=torch.float64, device=\"cuda:0\")\n",
            "<ipython-input-4-8ebaba95c783>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test = torch.tensor(x_test,dtype=torch.float64,device=\"cuda:0\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbAgU3LWkm_5",
        "outputId": "974156c5-5084-4715-ff18-f7599fa894c8"
      },
      "source": [
        "print(\"shape of x_train :\",x_train.shape)\n",
        "print(\"shape of y_train :\",y_train.shape)\n",
        "print(\"shape of x_test :\",x_test.shape)\n",
        "print(\"shape of y_test :\",y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x_train : torch.Size([5000, 784])\n",
            "shape of y_train : torch.Size([5000])\n",
            "shape of x_test : torch.Size([1000, 784])\n",
            "shape of y_test : torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training"
      ],
      "metadata": {
        "id": "X-FhRaxEzIU2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUvdSR94v5V",
        "outputId": "181fec86-8e71-4e68-f682-4292c93feea0"
      },
      "source": [
        "N = x_train.shape[0]\n",
        "input_size = x_train.shape[1]\n",
        "\n",
        "#---------과제---------#\n",
        "\n",
        "## 고정 변수\n",
        "output_size = 10 # output target 종류의 개수 mnist 데이터 클래스 10개 (고정)\n",
        "\n",
        "epoch_size = 10 # 학습 수\n",
        "hidden_size_one= 128\n",
        "hidden_size_two= 64\n",
        "\n",
        "## 실험 할 값\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "results_lr = {}\n",
        "\n",
        "#---------과제---------#\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "\n",
        "  Network = ThreeLayerNet(input_size=input_size, hidden_size_one=hidden_size_one,hidden_size_two=hidden_size_two,output_size=output_size)\n",
        "  Network = Network.cuda()\n",
        "  history = {'val_acc': [],'val_loss': []}\n",
        "\n",
        "  #loss 와 optimzer 선언\n",
        "  optimizer = torch.optim.SGD(Network.parameters(), lr=learning_rate)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  #코드를 보며 epoch, batch에 대해서 이해해봅시다.\n",
        "  for i in range(epoch_size+1):\n",
        "      for j in range(N):\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          x_now = x_train[j].unsqueeze(0).type(torch.cuda.FloatTensor)\n",
        "          y_now = y_train[j].unsqueeze(0)\n",
        "\n",
        "          y_predict = Network(x_now)\n",
        "\n",
        "          #---------과제---------#\n",
        "          #loss 계산 후 weight update#\n",
        "          #---------과제---------#\n",
        "\n",
        "          # loss 계산\n",
        "          loss=criterion(y_predict,y_now)\n",
        "\n",
        "          # BP\n",
        "          loss.backward()\n",
        "\n",
        "          # weight update := optimizer\n",
        "          optimizer.step()\n",
        "\n",
        "      #accuracy와 loss를 기록해둡시다.\n",
        "      val_acc = 0\n",
        "      val_loss = 0\n",
        "      for k in range(x_test.shape[0]):\n",
        "          val_acc += Network.accuracy(x_test[k].unsqueeze(0).type(torch.cuda.FloatTensor), y_test[k])\n",
        "          val_loss += criterion((Network.forward(x_test[k].unsqueeze(0).type(torch.cuda.FloatTensor))), y_test[k].unsqueeze(0)).detach()\n",
        "      history[\"val_acc\"].append((val_acc/x_test.shape[0]).cpu())\n",
        "      history[\"val_loss\"].append((val_loss/x_test.shape[0]).cpu())\n",
        "\n",
        "      if i % 10 == 0:\n",
        "          print(\"============================================\")\n",
        "          print(\"learning_rate:\",learning_rate)\n",
        "          print(i, \"train accuracy :\", Network.accuracy(x_train.type(torch.cuda.FloatTensor), y_train))\n",
        "          print(i, \"train loss     :\", loss)\n",
        "          print(i, \"test accuracy :\", val_acc/x_test.shape[0])\n",
        "          print(i, \"test loss     :\", val_loss/x_test.shape[0])\n",
        "          print(\"============================================\")\n",
        "\n",
        "      results_lr[learning_rate] = {'final_acc': history['val_acc'][-1], 'final_loss': history['val_loss'][-1], 'history': history}\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================\n",
            "learning_rate: 0.1\n",
            "0 train accuracy : tensor(18.3200, device='cuda:0')\n",
            "0 train loss     : tensor(2.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "0 test accuracy : tensor(16.4000, device='cuda:0')\n",
            "0 test loss     : tensor(2.1676, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.1\n",
            "10 train accuracy : tensor(17.2200, device='cuda:0')\n",
            "10 train loss     : tensor(2.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10 test accuracy : tensor(16.6000, device='cuda:0')\n",
            "10 test loss     : tensor(2.0809, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.01\n",
            "0 train accuracy : tensor(56.3400, device='cuda:0')\n",
            "0 train loss     : tensor(0.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "0 test accuracy : tensor(55.5000, device='cuda:0')\n",
            "0 test loss     : tensor(1.2205, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.01\n",
            "10 train accuracy : tensor(69.3800, device='cuda:0')\n",
            "10 train loss     : tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10 test accuracy : tensor(65.8000, device='cuda:0')\n",
            "10 test loss     : tensor(0.8939, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.001\n",
            "0 train accuracy : tensor(33.4600, device='cuda:0')\n",
            "0 train loss     : tensor(2.2219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "0 test accuracy : tensor(33.9000, device='cuda:0')\n",
            "0 test loss     : tensor(2.2243, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.001\n",
            "10 train accuracy : tensor(47.9000, device='cuda:0')\n",
            "10 train loss     : tensor(0.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10 test accuracy : tensor(48.3000, device='cuda:0')\n",
            "10 test loss     : tensor(1.3542, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.0001\n",
            "0 train accuracy : tensor(9.6600, device='cuda:0')\n",
            "0 train loss     : tensor(2.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "0 test accuracy : tensor(8.5000, device='cuda:0')\n",
            "0 test loss     : tensor(2.2997, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 0.0001\n",
            "10 train accuracy : tensor(33.6600, device='cuda:0')\n",
            "10 train loss     : tensor(2.2059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10 test accuracy : tensor(33.8000, device='cuda:0')\n",
            "10 test loss     : tensor(2.2060, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 1e-05\n",
            "0 train accuracy : tensor(9.6000, device='cuda:0')\n",
            "0 train loss     : tensor(2.3028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "0 test accuracy : tensor(8.4000, device='cuda:0')\n",
            "0 test loss     : tensor(2.3037, device='cuda:0')\n",
            "============================================\n",
            "============================================\n",
            "learning_rate: 1e-05\n",
            "10 train accuracy : tensor(9.6600, device='cuda:0')\n",
            "10 train loss     : tensor(2.2943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10 test accuracy : tensor(8.6000, device='cuda:0')\n",
            "10 test loss     : tensor(2.2992, device='cuda:0')\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-l2ADt4bmJr",
        "outputId": "fc7786d7-c819-4a20-9388-e95fa3f99135"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.1: {'final_acc': tensor(16.6000),\n",
              "  'final_loss': tensor(2.0809),\n",
              "  'history': {'val_acc': [tensor(16.4000),\n",
              "    tensor(25.5000),\n",
              "    tensor(20.9000),\n",
              "    tensor(18.3000),\n",
              "    tensor(17.7000),\n",
              "    tensor(17.8000),\n",
              "    tensor(15.3000),\n",
              "    tensor(16.9000),\n",
              "    tensor(17.9000),\n",
              "    tensor(14.6000),\n",
              "    tensor(16.6000)],\n",
              "   'val_loss': [tensor(2.1676),\n",
              "    tensor(1.9832),\n",
              "    tensor(2.0797),\n",
              "    tensor(2.0678),\n",
              "    tensor(2.1058),\n",
              "    tensor(2.1038),\n",
              "    tensor(2.1003),\n",
              "    tensor(2.1267),\n",
              "    tensor(2.1150),\n",
              "    tensor(2.1061),\n",
              "    tensor(2.0809)]}},\n",
              " 0.01: {'final_acc': tensor(65.8000),\n",
              "  'final_loss': tensor(0.8939),\n",
              "  'history': {'val_acc': [tensor(55.5000),\n",
              "    tensor(55.9000),\n",
              "    tensor(56.5000),\n",
              "    tensor(64.1000),\n",
              "    tensor(65.1000),\n",
              "    tensor(65.7000),\n",
              "    tensor(64.7000),\n",
              "    tensor(65.7000),\n",
              "    tensor(65.5000),\n",
              "    tensor(65.5000),\n",
              "    tensor(65.8000)],\n",
              "   'val_loss': [tensor(1.2205),\n",
              "    tensor(1.1286),\n",
              "    tensor(1.0979),\n",
              "    tensor(1.0426),\n",
              "    tensor(0.9227),\n",
              "    tensor(0.8948),\n",
              "    tensor(0.9041),\n",
              "    tensor(0.8993),\n",
              "    tensor(0.8910),\n",
              "    tensor(0.8903),\n",
              "    tensor(0.8939)]}},\n",
              " 0.001: {'final_acc': tensor(48.3000),\n",
              "  'final_loss': tensor(1.3542),\n",
              "  'history': {'val_acc': [tensor(33.9000),\n",
              "    tensor(38.6000),\n",
              "    tensor(40.7000),\n",
              "    tensor(45.5000),\n",
              "    tensor(47.0000),\n",
              "    tensor(47.8000),\n",
              "    tensor(47.8000),\n",
              "    tensor(48.0000),\n",
              "    tensor(48.2000),\n",
              "    tensor(48.2000),\n",
              "    tensor(48.3000)],\n",
              "   'val_loss': [tensor(2.2243),\n",
              "    tensor(1.9926),\n",
              "    tensor(1.6883),\n",
              "    tensor(1.5653),\n",
              "    tensor(1.4942),\n",
              "    tensor(1.4473),\n",
              "    tensor(1.4160),\n",
              "    tensor(1.3939),\n",
              "    tensor(1.3777),\n",
              "    tensor(1.3648),\n",
              "    tensor(1.3542)]}},\n",
              " 0.0001: {'final_acc': tensor(33.8000),\n",
              "  'final_loss': tensor(2.2060),\n",
              "  'history': {'val_acc': [tensor(8.5000),\n",
              "    tensor(9.1000),\n",
              "    tensor(11.5000),\n",
              "    tensor(16.4000),\n",
              "    tensor(22.4000),\n",
              "    tensor(27.7000),\n",
              "    tensor(30.8000),\n",
              "    tensor(32.7000),\n",
              "    tensor(34.3000),\n",
              "    tensor(34.3000),\n",
              "    tensor(33.8000)],\n",
              "   'val_loss': [tensor(2.2997),\n",
              "    tensor(2.2950),\n",
              "    tensor(2.2899),\n",
              "    tensor(2.2844),\n",
              "    tensor(2.2783),\n",
              "    tensor(2.2711),\n",
              "    tensor(2.2626),\n",
              "    tensor(2.2523),\n",
              "    tensor(2.2397),\n",
              "    tensor(2.2244),\n",
              "    tensor(2.2060)]}},\n",
              " 1e-05: {'final_acc': tensor(8.6000),\n",
              "  'final_loss': tensor(2.2992),\n",
              "  'history': {'val_acc': [tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.4000),\n",
              "    tensor(8.5000),\n",
              "    tensor(8.5000),\n",
              "    tensor(8.6000)],\n",
              "   'val_loss': [tensor(2.3037),\n",
              "    tensor(2.3033),\n",
              "    tensor(2.3028),\n",
              "    tensor(2.3024),\n",
              "    tensor(2.3020),\n",
              "    tensor(2.3015),\n",
              "    tensor(2.3011),\n",
              "    tensor(2.3006),\n",
              "    tensor(2.3001),\n",
              "    tensor(2.2997),\n",
              "    tensor(2.2992)]}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z9463goSk8pP"
      }
    }
  ]
}